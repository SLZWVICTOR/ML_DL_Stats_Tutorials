{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#LSTM-based autoencoder\n",
    "import pandas as pd\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#through this exercise, it is clear, there are a few lessons:\n",
    "#(1) it is not easy to get the dimensions right easily;\n",
    "#(2) to process sequence data, I will need to the following:\n",
    "#    map sequence (characters) to integers\n",
    "#    pad the sequences\n",
    "#    one hot encoding (convert to categorical) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_clean_kd_data.py             get_smiles_from_inchikey.nb.html\n",
      "get_smiles_from_inchikey.Rmd     inchikey_inchi_smiles.tab\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/hbi16859/Desktop/explore/AI_Pilot/challenges/challenge_code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inchikey\tinchi\tsmiles\n",
      "WUEKQBWOLUXRLC-IUCAKERBSA-N\tInChI=1S/C12H19N3O5/c1-7(16)14-8(4-5-10(17)18)12(20)15-6-2-3-9(15)11(13)19/h8-9H,2-6H2,1H3,(H2,13,19)(H,14,16)(H,17,18)/t8-,9-/m0/s1\tCC(=N[C@@H](CCC(=O)O)C(=O)N1CCC[C@H]1C(=N)O)O\n",
      "WUEUSIZSEGWDFF-QRBPUMSVSA-N\tInChI=1S/C46H60N6O8/c1-28(2)22-35(49-43(56)38(52-45(59)60-46(5,6)7)26-32-27-47-34-21-15-14-20-33(32)34)40(53)50-37(24-30-16-10-8-11-17-30)42(55)48-36(23-29(3)4)41(54)51-39(44(57)58)25-31-18-12-9-13-19-31/h8-21,27-29,35-39,47H,22-26H2,1-7H3,(H,48,55)(H,49,56)(H,50,53)(H,51,54)(H,52,59)(H,57,58)/t35-,36-,37+,38+,39+/m1/s1\tCC(C)C[C@H](C(=N[C@@H](Cc1ccccc1)C(=N[C@H](CC(C)C)C(=N[C@@H](Cc1ccccc1)C(=O)O)O)O)O)N=C([C@H](Cc1c[nH]c2ccccc12)N=C(O)OC(C)(C)C)O\n",
      "WUGANDSUVKXMEC-UHFFFAOYSA-N\tInChI=1S/C18H14BrNO5S2/c19-11-5-7-12(8-6-11)27(24,25)20-15-9-16(26-10-17(21)22)18(23)14-4-2-1-3-13(14)15/h1-9,20,23H,10H2,(H,21,22)\tc1ccc2c(c1)c(cc(c2O)SCC(=O)O)NS(=O)(=O)c1ccc(cc1)Br\n",
      "WUGDAJPNWXMGLH-CQJMVLFOSA-N\tInChI=1S/C34H44N7O12PS/c35-27(43)16-25-31(47)38-23(14-19-4-8-21(42)9-5-19)30(46)39-26(29(36)45)17-55-18-28(44)37-24(15-20-6-10-22(11-7-20)53-54(50,51)52)32(48)41-34(33(49)40-25)12-2-1-3-13-34/h4-11,23-26,42H,1-3,12-18H2,(H2,35,43)(H2,36,45)(H,37,44)(H,38,47)(H,39,46)(H,40,49)(H,41,48)(H2,50,51,52)/t23-,24-,25-,26-/m0/s1\tC1CCC2(CC1)C(=N[C@@H](CC(=N)O)C(=N[C@@H](Cc1ccc(cc1)O)C(=N[C@@H](CSCC(=N[C@@H](Cc1ccc(cc1)OP(=O)(O)O)C(=N2)O)O)C(=N)O)O)O)O\n"
     ]
    }
   ],
   "source": [
    "!head -n5 /Users/hbi16859/Desktop/explore/AI_Pilot/challenges/challenge_code/inchikey_inchi_smiles.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/hbi16859/Desktop/explore/AI_Pilot/challenges/challenge_code/inchikey_inchi_smiles.tab\",sep=\"\\t\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles=df[\"smiles\"].dropna().apply(lambda x: [i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1=smiles.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list=[]\n",
    "for sublist in array1:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(flat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '(',\n",
       " ')',\n",
       " '+',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '=',\n",
       " '@',\n",
       " 'B',\n",
       " 'C',\n",
       " 'F',\n",
       " 'H',\n",
       " 'I',\n",
       " 'K',\n",
       " 'L',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'S',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " 'a',\n",
       " 'c',\n",
       " 'e',\n",
       " 'i',\n",
       " 'l',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 's']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=np.asarray(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1.reshap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for line in array1:\n",
    "    # integer encode line\n",
    "    encoded_seq = [mapping[char] for char in line]\n",
    "    # store\n",
    "    sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 39\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(mapping)\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in sequences2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing \n",
    "#I should do padding before I do the one hot encoding (otherwisem the sequences are in higher dimensional \n",
    "representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 2, 3, 4, 6],\n",
       "       [0, 0, 0, 0, 0, 3, 4, 5]], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.preprocessing.sequence.pad_sequences([[1,2,3,4,6],[3,4,5]],maxlen=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq=keras.preprocessing.sequence.pad_sequences(sequences,maxlen=880) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_categ= [[tf.keras.utils.to_categorical(i,num_classes=vocab_size+1) for i in subseq] for subseq in padded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_categ=np.asarray(seq_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 880, 40)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_categ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(880,40)))  #the inputs are (1794,880,40), so the dims match\n",
    "model.add(RepeatVector(880))  #this number 880 needs to match with the input shape 880\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(40)))  #this number 40 needs to match with the input shape 40\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_47 (LSTM)               (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_23 (RepeatVect (None, 880, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 880, 100)          80400     \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 880, 40)           4040      \n",
      "=================================================================\n",
      "Total params: 140,840\n",
      "Trainable params: 140,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x188a8f0080>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "#this does not work because of the dimensions\n",
    "model.fit(seq_categ, seq_categ, epochs=2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 40)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_categ[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18948cecf8>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(seq_categ[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=model.predict(seq_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1894a88f98>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(results[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just trained the data for 2 epochs, I do not think the model is very good at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.94621961],\n",
       "       [0.94621961, 1.        ]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(seq_categ[100].flatten(),results[100].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.86787863],\n",
       "       [0.86787863, 1.        ]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(seq_categ[500].flatten(),results[500].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "\n",
    "timesteps=880\n",
    "input_dim=40\n",
    "latent_dim=502\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 880, 40)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_categ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 880)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq2=padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq2=padded_seq2.reshape(1794,880,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18975f2d68>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what about without the one-hot encoding\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(100, activation='relu', input_shape=(880,1)))\n",
    "model2.add(RepeatVector(880))\n",
    "model2.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model2.add(TimeDistributed(Dense(1)))\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model2.fit(padded_seq2, padded_seq2, epochs=2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-2e16017fa03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_seq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model2.layers[0:2].predict(padded_seq2[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "repeat_vector_27 (RepeatVect (None, 880, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 880, 100)          80400     \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 880, 1)            101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        ...,\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]],\n",
       "\n",
       "       [[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        ...,\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]]], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(padded_seq2[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##let me try this tomorrow to assign weights\n",
    "\n",
    "Using save_weights(), and load_weights() works.\n",
    "You can also use model.get_layer( either by name or index) to get the layer and you can then call get_weights() or set_weights(). And do the mapping by matching names.\n",
    "\n",
    "Alternatively when the structure of the network is known :\n",
    "Usually when you build a network, you can return a tuple of model\n",
    "(combined_network, subnetwork1, subnetwork2 ) which all share the same shared variables\n",
    "\n",
    "If you need to transfer the weights you to another network or subnetwork for which you have a tuple.\n",
    "(new_combined_network, new_subnetwork1, new_subnetwork2)\n",
    "\n",
    "doing new_combined_network.set_weights( combined_network.get_weights() ) will set all the weights including the subnetworks.\n",
    "\n",
    "doing new_subnetwork1.set_weights( subnetwork1.get_weights()) will only transfer the weight of the subnetwork1\n",
    "\n",
    "model.layers[i].set_weights(listOfNumpyArrays)    \n",
    "model.get_layer(layerName).set_weights(...)\n",
    "model.set_weights(listOfNumpyArrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
